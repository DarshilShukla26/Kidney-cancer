{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"94iLyr4QI-i2","executionInfo":{"status":"ok","timestamp":1697812522349,"user_tz":-330,"elapsed":8,"user":{"displayName":"Shrey Puvar","userId":"05479543989701848934"}}},"outputs":[],"source":["import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a4Ot93s7I-i_","executionInfo":{"status":"ok","timestamp":1697812970487,"user_tz":-330,"elapsed":18634,"user":{"displayName":"Shrey Puvar","userId":"05479543989701848934"}},"outputId":"07bf19f9-a175-473c-ff19-4a5a744ab7da"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"i5hMNJDqI-jA","executionInfo":{"status":"ok","timestamp":1697812970488,"user_tz":-330,"elapsed":6,"user":{"displayName":"Shrey Puvar","userId":"05479543989701848934"}}},"outputs":[],"source":["%matplotlib inline\n","%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"M6NIRE-fI-jE","executionInfo":{"status":"ok","timestamp":1697812986829,"user_tz":-330,"elapsed":16346,"user":{"displayName":"Shrey Puvar","userId":"05479543989701848934"}}},"outputs":[],"source":["import zipfile\n","zip_ref = zipfile.ZipFile(\"/content/drive/MyDrive/dataset/data_1.zip\",\"r\")\n","zip_ref.extractall(\"./\")\n","zip_ref.close()"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-OguqdX9I-jE","executionInfo":{"status":"ok","timestamp":1697813007900,"user_tz":-330,"elapsed":21089,"user":{"displayName":"Shrey Puvar","userId":"05479543989701848934"}},"outputId":"286cabf5-ab08-4db2-c81b-aa1bae8710bf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting split-folders\n","  Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n","Installing collected packages: split-folders\n","Successfully installed split-folders-0.5.1\n","\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow==2.3.1 (from versions: 2.8.0rc0, 2.8.0rc1, 2.8.0, 2.8.1, 2.8.2, 2.8.3, 2.8.4, 2.9.0rc0, 2.9.0rc1, 2.9.0rc2, 2.9.0, 2.9.1, 2.9.2, 2.9.3, 2.10.0rc0, 2.10.0rc1, 2.10.0rc2, 2.10.0rc3, 2.10.0, 2.10.1, 2.11.0rc0, 2.11.0rc1, 2.11.0rc2, 2.11.0, 2.11.1, 2.12.0rc0, 2.12.0rc1, 2.12.0, 2.12.1, 2.13.0rc0, 2.13.0rc1, 2.13.0rc2, 2.13.0, 2.13.1, 2.14.0rc0, 2.14.0rc1, 2.14.0)\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow==2.3.1\u001b[0m\u001b[31m\n","\u001b[0mCollecting tensorflow-datasets==4.0.0\n","  Downloading tensorflow_datasets-4.0.0-py3-none-any.whl (3.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets==4.0.0) (1.4.0)\n","Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets==4.0.0) (23.1.0)\n","Collecting dill (from tensorflow-datasets==4.0.0)\n","  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets==4.0.0) (0.1.8)\n","Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets==4.0.0) (0.18.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets==4.0.0) (1.23.5)\n","Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets==4.0.0) (2.3)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets==4.0.0) (3.20.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets==4.0.0) (2.31.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets==4.0.0) (1.16.0)\n","Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets==4.0.0) (1.14.0)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets==4.0.0) (2.3.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets==4.0.0) (4.66.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets==4.0.0) (3.3.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets==4.0.0) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets==4.0.0) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets==4.0.0) (2023.7.22)\n","Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-metadata->tensorflow-datasets==4.0.0) (1.61.0)\n","Installing collected packages: dill, tensorflow-datasets\n","  Attempting uninstall: tensorflow-datasets\n","    Found existing installation: tensorflow-datasets 4.9.3\n","    Uninstalling tensorflow-datasets-4.9.3:\n","      Successfully uninstalled tensorflow-datasets-4.9.3\n","Successfully installed dill-0.3.7 tensorflow-datasets-4.0.0\n","Collecting tensorflow-addons\n","  Downloading tensorflow_addons-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (612 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m612.3/612.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (23.2)\n","Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons)\n","  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n","Installing collected packages: typeguard, tensorflow-addons\n","Successfully installed tensorflow-addons-0.22.0 typeguard-2.13.3\n"]}],"source":["!pip install split-folders\n","!pip install tensorflow==2.3.1\n","!pip install tensorflow-datasets==4.0.0\n","!pip install tensorflow-addons"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"J9I7xyxmI-jF","executionInfo":{"status":"ok","timestamp":1697813010963,"user_tz":-330,"elapsed":3080,"user":{"displayName":"Shrey Puvar","userId":"05479543989701848934"}}},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import splitfolders\n","import tensorflow as tf\n","from tensorflow import keras\n","from keras import Sequential\n","import math\n","import random\n","import os"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"ZCtYnNXnI-jF","executionInfo":{"status":"ok","timestamp":1697813010964,"user_tz":-330,"elapsed":9,"user":{"displayName":"Shrey Puvar","userId":"05479543989701848934"}}},"outputs":[],"source":["# count the number of images in the respective classes 1 - Kidney tumor and 0 - Normal\n","ROOT_DIR =\"/content/data/\""]},{"cell_type":"code","execution_count":9,"metadata":{"id":"v_rgqCLNI-jG","executionInfo":{"status":"ok","timestamp":1697813010964,"user_tz":-330,"elapsed":8,"user":{"displayName":"Shrey Puvar","userId":"05479543989701848934"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"3a799143-f983-41dd-890e-ce1152ca94d9"},"outputs":[{"output_type":"stream","name":"stderr","text":["Copying files: 0 files [00:00, ? files/s]\n"]}],"source":["splitfolders.ratio(ROOT_DIR,output=\"splited_data\",\n","                   seed=42,\n","                   ratio=(.7,.0,.3),\n","                   group_prefix=None)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":418},"id":"fgVW7vMuI-jH","executionInfo":{"status":"error","timestamp":1697813076112,"user_tz":-330,"elapsed":719,"user":{"displayName":"Shrey Puvar","userId":"05479543989701848934"}},"outputId":"41d068fd-de8e-4757-8979-577e5a1c10ca"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 0 files belonging to 1 classes.\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-1406cf1457d0>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# generators\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m train_ds = tf.keras.utils.image_dataset_from_directory(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mdirectory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/content/splited_data/train\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"inferred\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mlabel_mode\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m\"int\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/image_dataset.py\u001b[0m in \u001b[0;36mimage_dataset_from_directory\u001b[0;34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links, crop_to_aspect_ratio, **kwargs)\u001b[0m\n\u001b[1;32m    297\u001b[0m         )\n\u001b[1;32m    298\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mimage_paths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    300\u001b[0m                 \u001b[0;34mf\"No images found in directory {directory}. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                 \u001b[0;34mf\"Allowed formats: {ALLOWLIST_FORMATS}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: No images found in directory /content/splited_data/train. Allowed formats: ('.bmp', '.gif', '.jpeg', '.jpg', '.png')"]}],"source":["# generators\n","train_ds = tf.keras.utils.image_dataset_from_directory(\n","    directory=\"/content/splited_data/train\",\n","    labels = \"inferred\",\n","    label_mode =\"int\",\n","    batch_size=16,\n","    image_size=(128,128)\n",")\n","\n","test_ds = tf.keras.utils.image_dataset_from_directory(\n","    directory=\"/content/splited_data/test\",\n","    labels = \"inferred\",\n","    label_mode =\"int\",\n","    batch_size=16,\n","    image_size=(128,128)\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E9JkRaMUI-jI","executionInfo":{"status":"aborted","timestamp":1697813011472,"user_tz":-330,"elapsed":7,"user":{"displayName":"Shrey Puvar","userId":"05479543989701848934"}}},"outputs":[],"source":["# Normalize\n","def process(image,label):\n","  image = tf.cast(image/255.,tf.float32)\n","  return image,label\n","\n","train_ds = train_ds.map(process)\n","test_ds = test_ds.map(process)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mi-yxebnI-jK","executionInfo":{"status":"aborted","timestamp":1697813011473,"user_tz":-330,"elapsed":7,"user":{"displayName":"Shrey Puvar","userId":"05479543989701848934"}}},"outputs":[],"source":["import tensorflow as tf\n","import tensorflow_addons as tfa\n","from tensorflow.keras.layers import (\n","    Dense,\n","    Dropout,\n","    LayerNormalization,\n",")\n","from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n","\n","\n","class MultiHeadSelfAttention(tf.keras.layers.Layer):\n","    def __init__(self, embed_dim, num_heads=8):\n","        super(MultiHeadSelfAttention, self).__init__()\n","        self.embed_dim = embed_dim\n","        self.num_heads = num_heads\n","        if embed_dim % num_heads != 0:\n","            raise ValueError(\n","                f\"embedding dimension = {embed_dim} should be divisible by number of heads = {num_heads}\"\n","            )\n","        self.projection_dim = embed_dim // num_heads\n","        self.query_dense = Dense(embed_dim)\n","        self.key_dense = Dense(embed_dim)\n","        self.value_dense = Dense(embed_dim)\n","        self.combine_heads = Dense(embed_dim)\n","\n","    def attention(self, query, key, value):\n","        score = tf.matmul(query, key, transpose_b=True)\n","        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n","        scaled_score = score / tf.math.sqrt(dim_key)\n","        weights = tf.nn.softmax(scaled_score, axis=-1)\n","        output = tf.matmul(weights, value)\n","        return output, weights\n","\n","    def separate_heads(self, x, batch_size):\n","        x = tf.reshape(\n","            x, (batch_size, -1, self.num_heads, self.projection_dim)\n","        )\n","        return tf.transpose(x, perm=[0, 2, 1, 3])\n","\n","    def call(self, inputs):\n","        batch_size = tf.shape(inputs)[0]\n","        query = self.query_dense(inputs)\n","        key = self.key_dense(inputs)\n","        value = self.value_dense(inputs)\n","        query = self.separate_heads(query, batch_size)\n","        key = self.separate_heads(key, batch_size)\n","        value = self.separate_heads(value, batch_size)\n","\n","        attention, weights = self.attention(query, key, value)\n","        attention = tf.transpose(attention, perm=[0, 2, 1, 3])\n","        concat_attention = tf.reshape(\n","            attention, (batch_size, -1, self.embed_dim)\n","        )\n","        output = self.combine_heads(concat_attention)\n","        return output\n","\n","\n","class TransformerBlock(tf.keras.layers.Layer):\n","    def __init__(self, embed_dim, num_heads, mlp_dim, dropout=0.1):\n","        super(TransformerBlock, self).__init__()\n","        self.att = MultiHeadSelfAttention(embed_dim, num_heads)\n","        self.mlp = tf.keras.Sequential(\n","            [\n","                Dense(mlp_dim, activation=tfa.activations.gelu),\n","                Dropout(dropout),\n","                Dense(embed_dim),\n","                Dropout(dropout),\n","            ]\n","        )\n","        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n","        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n","        self.dropout1 = Dropout(dropout)\n","        self.dropout2 = Dropout(dropout)\n","\n","    def call(self, inputs, training):\n","        inputs_norm = self.layernorm1(inputs)\n","        attn_output = self.att(inputs_norm)\n","        attn_output = self.dropout1(attn_output, training=training)\n","        out1 = attn_output + inputs\n","\n","        out1_norm = self.layernorm2(out1)\n","        mlp_output = self.mlp(out1_norm)\n","        mlp_output = self.dropout2(mlp_output, training=training)\n","        return mlp_output + out1\n","\n","\n","class VisionTransformer(tf.keras.Model):\n","    def __init__(\n","        self,\n","        image_size,\n","        patch_size,\n","        num_layers,\n","        num_classes,\n","        d_model,\n","        num_heads,\n","        mlp_dim,\n","        channels=3,\n","        dropout=0.1,\n","    ):\n","        super(VisionTransformer, self).__init__()\n","        num_patches = (image_size // patch_size) ** 2\n","        self.patch_dim = channels * patch_size ** 2\n","\n","        self.patch_size = patch_size\n","        self.d_model = d_model\n","        self.num_layers = num_layers\n","\n","        self.rescale = Rescaling(1.0 / 255)\n","        self.pos_emb = self.add_weight(\n","            \"pos_emb\", shape=(1, num_patches + 1, d_model)\n","        )\n","        self.class_emb = self.add_weight(\"class_emb\", shape=(1, 1, d_model))\n","        self.patch_proj = Dense(d_model)\n","        self.enc_layers = [\n","            TransformerBlock(d_model, num_heads, mlp_dim, dropout)\n","            for _ in range(num_layers)\n","        ]\n","        self.mlp_head = tf.keras.Sequential(\n","            [\n","                LayerNormalization(epsilon=1e-6),\n","                Dense(mlp_dim, activation=tfa.activations.gelu),\n","                Dropout(dropout),\n","                Dense(num_classes-1),\n","            ]\n","        )\n","\n","    def extract_patches(self, images):\n","        batch_size = tf.shape(images)[0]\n","        patches = tf.image.extract_patches(\n","            images=images,\n","            sizes=[1, self.patch_size, self.patch_size, 1],\n","            strides=[1, self.patch_size, self.patch_size, 1],\n","            rates=[1, 1, 1, 1],\n","            padding=\"VALID\",\n","        )\n","        patches = tf.reshape(patches, [batch_size, -1, self.patch_dim])\n","        return patches\n","\n","    def call(self, x, training):\n","        batch_size = tf.shape(x)[0]\n","        x = self.rescale(x)\n","        patches = self.extract_patches(x)\n","        x = self.patch_proj(patches)\n","\n","        class_emb = tf.broadcast_to(\n","            self.class_emb, [batch_size, 1, self.d_model]\n","        )\n","        x = tf.concat([class_emb, x], axis=1)\n","        x = x + self.pos_emb\n","\n","        for layer in self.enc_layers:\n","            x = layer(x, training)\n","\n","        # First (class token) is used for classification\n","        x = self.mlp_head(x[:, 0])\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vx5vikiiI-jM","executionInfo":{"status":"aborted","timestamp":1697813011473,"user_tz":-330,"elapsed":7,"user":{"displayName":"Shrey Puvar","userId":"05479543989701848934"}}},"outputs":[],"source":["# Path to the folders containing the images\n","normal_folder = '/content/splited_data/train/Normal'\n","tumor_folder = '/content/splited_data/train/Tumor'\n","\n","# Get the list of image filenames in the folders\n","normal_images = [os.path.join(normal_folder, filename) for filename in os.listdir(normal_folder)]\n","tumor_images = [os.path.join(tumor_folder, filename) for filename in os.listdir(tumor_folder)]\n","\n","# Combine the lists of images\n","all_images = normal_images + tumor_images\n","random.shuffle(all_images)  # Shuffle the images"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mN3_TNr5I-jM","executionInfo":{"status":"aborted","timestamp":1697813011473,"user_tz":-330,"elapsed":7,"user":{"displayName":"Shrey Puvar","userId":"05479543989701848934"}}},"outputs":[],"source":["# Function to plot images with a fixed size\n","def plotImages(image_paths, image_size=(256, 256)):\n","    fig, axes = plt.subplots(2, 5, figsize=(15, 7))\n","    for img_path, ax in zip(image_paths, axes.ravel()):\n","        img = plt.imread(img_path)\n","        ax.imshow(img, extent=[0, image_size[0], 0, image_size[1]])\n","        ax.set_title(os.path.basename(os.path.dirname(img_path)))\n","        ax.axis('off')\n","    plt.tight_layout()\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RowtaCCXI-jM","executionInfo":{"status":"aborted","timestamp":1697813011473,"user_tz":-330,"elapsed":7,"user":{"displayName":"Shrey Puvar","userId":"05479543989701848934"}}},"outputs":[],"source":["# Select 10 random images\n","selected_images = random.sample(all_images, 10)\n","\n","# Plot the selected images\n","plotImages(selected_images)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T8J6MLSZI-jN","executionInfo":{"status":"aborted","timestamp":1697813011473,"user_tz":-330,"elapsed":7,"user":{"displayName":"Shrey Puvar","userId":"05479543989701848934"}}},"outputs":[],"source":["import os\n","from argparse import ArgumentParser\n","\n","import tensorflow as tf\n","import tensorflow_addons as tfa\n","# import tensorflow_datasets as tfds\n","from tensorflow.keras.callbacks import TensorBoard\n","\n","\n","AUTOTUNE = tf.data.experimental.AUTOTUNE\n","\n","# if __name__ == \"__main__\":\n","#     parser = ArgumentParser()\n","#     parser.add_argument(\"--logdir\", default=\"logs\")\n","#     parser.add_argument(\"--image-size\", default=32, type=int)\n","#     parser.add_argument(\"--patch-size\", default=4, type=int)\n","#     parser.add_argument(\"--num-layers\", default=4, type=int)\n","#     parser.add_argument(\"--d-model\", default=64, type=int)\n","#     parser.add_argument(\"--num-heads\", default=4, type=int)\n","#     parser.add_argument(\"--mlp-dim\", default=128, type=int)\n","#     parser.add_argument(\"--lr\", default=3e-4, type=float)\n","#     parser.add_argument(\"--weight-decay\", default=1e-4, type=float)\n","#     parser.add_argument(\"--batch-size\", default=4096, type=int)\n","#     parser.add_argument(\"--epochs\", default=300, type=int)\n","#     args = parser.parse_args()\n","\n","args = {\n","    \"logdir\": \"logs\",\n","    \"image_size\": 128,\n","    \"patch_size\": 4,\n","    \"num_layers\": 4,\n","    \"d_model\": 64,\n","    \"num_heads\": 4,\n","    \"mlp_dim\": 128,\n","    \"lr\": 3e-4,\n","    \"weight_decay\": 1e-4,\n","    \"batch_size\": 16,\n","    \"epochs\": 50,\n","}\n","\n","\n","\n","#     ds = tfds.load(\"imagenet_resized/32x32\", as_supervised=True)\n","#     ds_train = (\n","#         ds[\"train\"]\n","#         .cache()\n","#         .shuffle(5 * args.batch_size)\n","#         .batch(args.batch_size)\n","#         .prefetch(AUTOTUNE)\n","#     )\n","#     ds_test = (\n","#         ds[\"validation\"]\n","#         .cache()\n","#         .batch(args.batch_size)\n","#         .prefetch(AUTOTUNE)\n","#     )\n","\n","#     strategy = tf.distribute.MirroredStrategy()\n","\n","#     with strategy.scope():\n","\n","# model = VisionTransformer(\n","#             image_size=args.image_size,\n","#             patch_size=args.patch_size,\n","#             num_layers=args.num_layers,\n","#             num_classes=2,\n","#             d_model=args.d_model,\n","#             num_heads=args.num_heads,\n","#             mlp_dim=args.mlp_dim,\n","#             channels=3,\n","#             dropout=0.1,\n","#         )\n","\n","model = VisionTransformer(\n","    image_size=args[\"image_size\"],\n","    patch_size=args[\"patch_size\"],\n","    num_layers=args[\"num_layers\"],\n","    num_classes=2,\n","    d_model=args[\"d_model\"],\n","    num_heads=args[\"num_heads\"],\n","    mlp_dim=args[\"mlp_dim\"],\n","    channels=3,\n","    dropout=0.1,\n",")\n","\n","# Build the model\n","model.build(input_shape=(None, args[\"image_size\"], args[\"image_size\"], 3))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W6hy-833I-jO","executionInfo":{"status":"aborted","timestamp":1697813011473,"user_tz":-330,"elapsed":7,"user":{"displayName":"Shrey Puvar","userId":"05479543989701848934"}}},"outputs":[],"source":["model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=['accuracy',tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kymGYF3cI-jO","executionInfo":{"status":"aborted","timestamp":1697813011473,"user_tz":-330,"elapsed":7,"user":{"displayName":"Shrey Puvar","userId":"05479543989701848934"}}},"outputs":[],"source":["model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HmOhic_9I-jO","executionInfo":{"status":"aborted","timestamp":1697813011474,"user_tz":-330,"elapsed":8,"user":{"displayName":"Shrey Puvar","userId":"05479543989701848934"}}},"outputs":[],"source":["hist=model.fit(\n","        train_ds,\n","        validation_data=test_ds,\n","        epochs=args['epochs'],\n","        # callbacks=[TensorBoard(log_dir=args['logdir'], profile_batch=0),],\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AiGxuZukI-jP","executionInfo":{"status":"aborted","timestamp":1697812949280,"user_tz":-330,"elapsed":10,"user":{"displayName":"Shrey Puvar","userId":"05479543989701848934"}}},"outputs":[],"source":["model.save_weights(os.path.join(args.logdir, \"vit\"))\n","# Save the model\n","model_save_path = '/content/drive/MyDrive/model/vit.h5'\n","model.save(model_save_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5TqWirFgI-jP"},"outputs":[],"source":["plt.plot(hist.history[\"loss\"],color=\"red\",label=\"train\")\n","plt.plot(hist.history['val_loss'],color=\"blue\",label=\"validation\")\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2AWJigYJI-jQ"},"outputs":[],"source":["plt.plot(hist.history[\"accuracy\"],color=\"red\",label=\"train\")\n","plt.plot(hist.history['val_accuracy'],color=\"blue\",label=\"validation\")\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7mI6j2dLI-jR"},"outputs":[],"source":["# Load the saved model\n","model_path = 'simple_cnn_with_attention.h5'\n","loaded_model = tf.keras.models.load_model(model_path)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.5"},"orig_nbformat":4,"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}